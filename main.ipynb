{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "!ls\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "pq_file = pq.ParquetFile(\"green_tripdata_2019-01.parquet\")\n",
    "print(pq_file.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bc94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "table = pq.read_table(\"green_tripdata_2019-01.parquet\")\n",
    "green_trips_df = table.to_pandas()\n",
    "green_trips_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc596d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_df = pd.read_csv(\"taxi_zone_lookup.csv\")\n",
    "zone_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "PG_user = \"lana\"\n",
    "PG_pass = \"1234\"\n",
    "PG_host = \"localhost\"\n",
    "PG_port = 5432\n",
    "PG_db = \"ny_taxi\"\n",
    "\n",
    "engine = create_engine(f\"postgresql://{PG_user}:{PG_pass}@{PG_host}:{PG_port}/{PG_db}\")\n",
    "con = engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df39c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4450b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator function to read parquet in chunks\n",
    "def read_parquet_in_chunks(file_path, chunksize=100000):\n",
    "    parquet_file = pq.ParquetFile(file_path)\n",
    "    for batch in parquet_file.iter_batches(batch_size=chunksize):\n",
    "        yield batch.to_pandas()\n",
    "\n",
    "# Iterator (mimics read_csv iterator)\n",
    "df_iter = read_parquet_in_chunks(\"green_tripdata_2019-01.parquet\", chunksize=10000)\n",
    "\n",
    "# Load first chunk\n",
    "df = next(df_iter)\n",
    "\n",
    "# Convert datetime columns\n",
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])\n",
    "\n",
    "# Create table schema in SQL database (replace with your SQLAlchemy connection object)\n",
    "df.head(0).to_sql(con=con, name=\"green_trip_data\", if_exists=\"replace\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(con=con, name=\"green_trip_data\", if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b64af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        t_start = time()\n",
    "        df = next(df_iter)\n",
    "\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.to_sql(con=con, name=\"green_trip_data\", if_exists=\"append\", index=False)\n",
    "\n",
    "        end_time = time()\n",
    "        print(\"New records added {}\".format(end_time - t_start))\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"All record imported or ingested\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VenV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
